#!/bin/bash

# =============================================================================
# Synthetic Bank End-to-End Deployment Script
# =============================================================================
# 
# This script provides complete end-to-end deployment of the synthetic bank:
# 1. Deploys all SQL files in the structure/ folder to Snowflake
# 2. Automatically uploads generated data to appropriate stages
# 3. Activates processing tasks for immediate operation
# 4. Deploys all Snowflake notebooks automatically
#
# Features:
# - Complete dependency-aware SQL deployment
# - Automatic data upload to correct stages
# - Task activation and monitoring
# - Automatic notebook deployment to Snowflake
# - Dry run mode for testing
# - Single file debugging support
#
# Usage:
#   ./deploy_structure.sh --DATABASE=AAA_DEV_SYNTHETIC_BANK --CONNECTION_NAME=my_connection [--upload-data=YES|NO]
#
# Examples:
#   ./deploy_structure.sh --DATABASE=AAA_DEV_SYNTHETIC_BANK --CONNECTION_NAME=<my-sf-connection>
#   ./deploy_structure.sh --DATABASE=AAA_DEV_SYNTHETIC_BANK --CONNECTION_NAME=<my-sf-connection> --upload-data=NO
# =============================================================================

set -e

# --- Default values ---
BASE_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
SQL_DIR="$BASE_DIR/structure"
UPLOAD_DATA="YES"

# --- Parse arguments ---
for ARG in "$@"; do
  case $ARG in
    --DATABASE=*)
      DATABASE="${ARG#*=}"
      ;;
    --CONNECTION_NAME=*)
      CONNECTION_NAME="${ARG#*=}"
      ;;
    --SQL_DIR=*)
      SQL_DIR="${ARG#*=}"
      ;;
    --FILE=*)
      SINGLE_FILE="${ARG#*=}"
      ;;
    --upload-data=*)
      UPLOAD_DATA="${ARG#*=}"
      if [[ "$UPLOAD_DATA" != "YES" && "$UPLOAD_DATA" != "NO" ]]; then
        echo "âŒ Invalid value for --upload-data: $UPLOAD_DATA (must be YES or NO)"
        exit 1
      fi
      ;;
    --DRY_RUN)
      DRY_RUN=true
      ;;
    *)
      echo "âŒ Unknown argument: $ARG"
      echo "Usage: $0 --DATABASE=... --CONNECTION_NAME=... [--SQL_DIR=...] [--FILE=...] [--upload-data=YES|NO] [--DRY_RUN]"
      exit 1
      ;;
  esac
done

# --- Validate required inputs ---
if [[ -z "$DATABASE" || -z "$CONNECTION_NAME" ]]; then
  echo "âŒ Missing required arguments."
  echo "Usage: $0 --DATABASE=... --CONNECTION_NAME=... [--SQL_DIR=...] [--FILE=...] [--upload-data=YES|NO] [--DRY_RUN]"
  echo ""
  echo "Arguments:"
  echo "  --DATABASE=...        Target database name"
  echo "  --CONNECTION_NAME=... Snowflake connection name"
  echo "  --SQL_DIR=...         Path to SQL files (default: ./structure)"
  echo "  --FILE=...            Test a single SQL file (e.g., 035_ICGI_swift_messages.sql)"
  echo "  --upload-data=YES|NO  Upload data after structure deployment (default: YES)"
  echo "  --DRY_RUN            Show what would be executed without running"
  exit 1
fi

if [[ ! -d "$SQL_DIR" ]]; then
  echo "âŒ Structure folder not found: $SQL_DIR"
  exit 1
fi

echo "ğŸš€ Snowflake Structure Deployment"
echo "=================================="
echo "ğŸ“ SQL Directory: $SQL_DIR"
echo "ğŸ—„ï¸  Database: $DATABASE"
echo "ğŸ”— Connection: $CONNECTION_NAME"
echo "ğŸ“¤ Upload Data: $UPLOAD_DATA"
if [[ "$DRY_RUN" == "true" ]]; then
  echo "ğŸ” Mode: DRY RUN (no actual execution)"
fi
echo ""

# --- Find and sort SQL files ---
if [[ -n "$SINGLE_FILE" ]]; then
  # Test a single file
  if [[ -f "$SQL_DIR/$SINGLE_FILE" ]]; then
    SQL_FILES="$SQL_DIR/$SINGLE_FILE"
    echo "ğŸ” Testing single file: $SINGLE_FILE"
  else
    echo "âŒ File not found: $SQL_DIR/$SINGLE_FILE"
    exit 1
  fi
else
  # Find all SQL files
  SQL_FILES=$(find "$SQL_DIR" -type f -name "*.sql" | sort)
  
  if [[ -z "$SQL_FILES" ]]; then
    echo "âŒ No SQL files found in $SQL_DIR"
    exit 0
  fi
fi

echo "ğŸ“„ Found SQL files:"
for FILE in $SQL_FILES; do
  echo "  - $(basename "$FILE")"
done
echo ""

# --- Execute each SQL file with USE statements prepended ---
for FILE in $SQL_FILES; do
  echo "ğŸ“ Processing: $(basename "$FILE")"
  
  # Create temporary file with SQL content
  TMP_FILE=$(mktemp)
  {
    # For 000_database_setup.sql, don't use the database (it creates it)
    if [[ "$(basename "$FILE")" == "000_database_setup.sql" ]]; then
      echo "SELECT"
      echo "  CURRENT_DATABASE() AS database_name,"
      echo "  CURRENT_SCHEMA() AS schema_name,"
      echo "  CURRENT_USER() AS current_user,"
      echo "  CURRENT_ROLE() AS current_role;"
      cat "$FILE"
    else
      echo "USE DATABASE $DATABASE;"
      echo "SELECT"
      echo "  CURRENT_DATABASE() AS database_name,"
      echo "  CURRENT_SCHEMA() AS schema_name,"
      echo "  CURRENT_USER() AS current_user,"
      echo "  CURRENT_ROLE() AS current_role;"
      cat "$FILE"
    fi
  } > "$TMP_FILE"

  # Always show the SQL content for debugging
  echo "   ğŸ“‹ SQL Content:"
  echo "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  if [[ "$(basename "$FILE")" == "000_database_setup.sql" ]]; then
    echo "   â”‚ [Database creation script - no USE DATABASE needed]"
  else
    echo "   â”‚ USE DATABASE $DATABASE;"
  fi
  echo "   â”‚ [Context info query]"
  echo "   â”‚ [Content of $(basename "$FILE")]"
  echo "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

  if [[ "$DRY_RUN" == "true" ]]; then
    echo "   ğŸ” DRY RUN - Would execute the above SQL"
    echo "   DRY RUN: $FILE"
  else
    echo "   ğŸš€ Executing SQL..."
    set +e
    snow sql -c "$CONNECTION_NAME" -f "$TMP_FILE" --enable-templating NONE
    RESULT=$?
    set -e

    if [[ $RESULT -ne 0 ]]; then
      # Special handling for Global Sanctions Data database already existing
      if [[ "$(basename "$FILE")" == "001_get_listings.sql" ]]; then
        echo "âš ï¸  Global Sanctions Data setup issue detected"
        echo "   This could be due to:"
        echo "   1. Database already exists (expected if previously imported)"
        echo "   2. Missing user profile information (first_name, last_name, email)"
        echo ""
        echo "ğŸ’¡ To fix user profile issue:"
        echo "   1. Go to Snowsight UI â†’ User Profile"
        echo "   2. Add First Name, Last Name, and Email"
        echo "   3. Or run: ALTER USER <username> SET first_name='John', last_name='Doe', email='john@company.com'"
        echo ""
        echo "   Continuing with deployment..."
        echo "Success: $(basename "$FILE") (setup issue handled)"
      else
        echo "âŒ Execution failed for: $(basename "$FILE")"
        echo "â›”ï¸ Aborting remaining scripts."
        rm "$TMP_FILE"
        exit 1
      fi
    else
      echo "Success: $(basename "$FILE")"
    fi
  fi

  rm "$TMP_FILE"

  echo ""
done

if [[ "$DRY_RUN" == "true" ]]; then
  echo "ğŸ” DRY RUN completed - no actual changes made"
else
  echo "ğŸ‰ All SQL scripts executed successfully!"
  
  # =============================================================================
  # NOTEBOOK DEPLOYMENT NOTE
  # =============================================================================
  # Notebooks will be automatically deployed after data upload completes
  if [[ -z "$SINGLE_FILE" ]]; then
    NOTEBOOKS_DIR="$BASE_DIR/notebooks"
    if [[ -d "$NOTEBOOKS_DIR" ]]; then
      NOTEBOOK_COUNT=$(find "$NOTEBOOKS_DIR" -maxdepth 1 -name "*.ipynb" -type f 2>/dev/null | wc -l | tr -d ' ')
      
      if [[ $NOTEBOOK_COUNT -gt 0 ]]; then
        echo ""
        echo "ğŸ““ Found $NOTEBOOK_COUNT notebook(s) - will deploy automatically after data processing"
        echo ""
      fi
    fi
  fi
  
  # =============================================================================
  # AUTOMATIC DATA UPLOAD AFTER SUCCESSFUL DEPLOYMENT
  # =============================================================================
  # Only trigger data upload for full deployments, not single file tests
  if [[ -z "$SINGLE_FILE" && "$UPLOAD_DATA" == "YES" ]]; then
    echo ""
    echo "ğŸ“¤ AUTOMATIC DATA UPLOAD"
    echo "========================"
    echo "ğŸš€ Structure deployment successful! Now uploading generated data..."
    echo ""
    
    # Check if upload-data.sh exists
    if [[ -f "./upload-data.sh" ]]; then
      echo "ğŸ“‹ Found upload-data.sh - Starting data upload..."
      echo ""
      
      # Execute the data upload script
      echo "ğŸ”„ Executing: ./upload-data.sh --CONNECTION_NAME=$CONNECTION_NAME"
      echo ""
      
      # Run the upload script
      ./upload-data.sh --CONNECTION_NAME="$CONNECTION_NAME"
      
      if [[ $? -eq 0 ]]; then
        echo ""
        echo "DATA UPLOAD COMPLETED SUCCESSFULLY!"
        echo ""
        
        # =============================================================================
        # AUTOMATIC TASK EXECUTION AND DT REFRESH
        # =============================================================================
        echo ""
        echo "âš™ï¸  EXECUTING TASKS AND REFRESHING DYNAMIC TABLES"
        echo "=================================================="
        echo "ğŸš€ Data uploaded successfully! Now loading and processing data..."
        echo ""
        
        # Check if execute script exists
        if [[ -f "./operation/execute_all_tasks_and_refresh_dts.sql" ]]; then
          echo "ğŸ“‹ Found execute_all_tasks_and_refresh_dts.sql - Starting data processing..."
          echo ""
          echo "â±ï¸  This will take 10-30 minutes depending on data volume..."
          echo "   â³ Step 1: Execute 14 RAW layer tasks (load from stages)"
          echo "   â³ Step 2: Refresh 26 AGG layer dynamic tables (transform)"
          echo "   â³ Step 3: Refresh 29 REP layer dynamic tables (reporting)"
          echo ""
          
          # Execute the tasks and refresh DTs
          echo "ğŸ”„ Executing: snow sql -c $CONNECTION_NAME -f ./operation/execute_all_tasks_and_refresh_dts.sql"
          echo ""
          
          # Run the execution script
          snow sql -c "$CONNECTION_NAME" -f ./operation/execute_all_tasks_and_refresh_dts.sql --enable-templating NONE
          
          if [[ $? -eq 0 ]]; then
            echo ""
            echo "TASK EXECUTION AND DT REFRESH COMPLETED!"
            echo ""
            echo "   All 14 tasks executed (data loaded from stages)"
            echo "   All 26 AGG layer DTs refreshed (data transformed)"
            echo "   All 29 REP layer DTs refreshed (reporting ready)"
            echo ""
          else
            echo ""
            echo "âš ï¸  Task execution partially failed - some operations may need manual retry"
            echo "ğŸ’¡ You can retry the execution manually:"
            echo "   snow sql -c $CONNECTION_NAME -f ./operation/execute_all_tasks_and_refresh_dts.sql"
            echo ""
          fi
        else
          echo "âš ï¸  operation/execute_all_tasks_and_refresh_dts.sql not found"
          echo "ğŸ’¡ To manually load and process data, run:"
          echo "   snow sql -c $CONNECTION_NAME -f ./operation/execute_all_tasks_and_refresh_dts.sql"
          echo ""
        fi
        
        echo ""
        echo "ğŸ¯ END-TO-END DEPLOYMENT SUMMARY:"
        echo "   âœ“ Database & schemas created"
        echo "   âœ“ All SQL objects deployed (incl. semantic views)"
        echo "   âœ“ Generated data uploaded to stages"
        echo "   âœ“ All 14 tasks executed (data loaded)"
        echo "   âœ“ All 55 dynamic tables refreshed (data processed)"
        echo ""
        
        # =============================================================================
        # AUTOMATIC NOTEBOOK DEPLOYMENT
        # =============================================================================
        echo ""
        echo "ğŸ““ DEPLOYING SNOWFLAKE NOTEBOOKS"
        echo "================================="
        echo "ğŸš€ Data processing complete! Now deploying notebooks..."
        echo ""
        
        # Check if deploy_notebooks.sh exists
        if [[ -f "./deploy_notebooks.sh" ]]; then
          echo "ğŸ“‹ Found deploy_notebooks.sh - Starting notebook deployment..."
          echo ""
          
          # Execute the notebook deployment script
          echo "ğŸ”„ Executing: ./deploy_notebooks.sh --DATABASE=$DATABASE --CONNECTION_NAME=$CONNECTION_NAME --SCHEMA=PUBLIC"
          echo ""
          
          # Run the notebook deployment script
          ./deploy_notebooks.sh --DATABASE="$DATABASE" --CONNECTION_NAME="$CONNECTION_NAME" --SCHEMA=PUBLIC
          
          if [[ $? -eq 0 ]]; then
            echo ""
            echo "NOTEBOOK DEPLOYMENT COMPLETED!"
            echo ""
          else
            echo ""
            echo "âš ï¸  Notebook deployment failed - notebooks may need manual deployment"
            echo "ğŸ’¡ You can retry the deployment manually:"
            echo "   ./deploy_notebooks.sh --DATABASE=$DATABASE --CONNECTION_NAME=$CONNECTION_NAME --SCHEMA=PUBLIC"
            echo ""
          fi
        else
          echo "âš ï¸  deploy_notebooks.sh not found - Skipping notebook deployment"
          echo "ğŸ’¡ To deploy notebooks manually, run:"
          echo "   ./deploy_notebooks.sh --DATABASE=$DATABASE --CONNECTION_NAME=$CONNECTION_NAME --SCHEMA=PUBLIC"
          echo ""
        fi
        
        echo ""
        echo "ğŸš€ Your synthetic bank is now fully operational with data loaded!"
        echo ""
        echo "Next steps:"
        echo "1. Verify data loaded: SELECT COUNT(*) FROM CRM_RAW_001.CRMI_RAW_TB_CUSTOMER;"
        echo "2. Check aggregations: SELECT * FROM CRM_AGG_001.CRMA_AGG_DT_CUSTOMER_360 LIMIT 10;"
        echo "3. Explore reports: SELECT * FROM REP_AGG_001.REPP_AGG_DT_CUSTOMER_SUMMARY LIMIT 10;"
        echo "4. Monitor tasks: SHOW TASKS IN DATABASE $DATABASE;"
        echo "5. Check semantic views: SHOW VIEWS LIKE '7%' IN DATABASE $DATABASE;"
        echo "6. Open notebooks: Snowsight â†’ Projects â†’ Notebooks â†’ $DATABASE.PUBLIC"
      else
        echo ""
        echo "âŒ Data upload failed! Please check the upload script output above."
        echo "ğŸ’¡ You can retry the upload manually:"
        echo "   ./upload-data.sh --CONNECTION_NAME=$CONNECTION_NAME"
      fi
    else
      echo "âš ï¸  upload-data.sh not found - Skipping data upload"
      echo "ğŸ’¡ To upload data manually, run:"
      echo "   ./upload-data.sh --CONNECTION_NAME=$CONNECTION_NAME"
    fi
  elif [[ -z "$SINGLE_FILE" && "$UPLOAD_DATA" == "NO" ]]; then
    echo ""
    echo "â­ï¸  Data upload skipped (--upload-data=NO)"
    echo "ğŸ’¡ To upload data manually later, run:"
    echo "   ./upload-data.sh --CONNECTION_NAME=$CONNECTION_NAME"
  else
    echo ""
    echo "ğŸ” Single file test completed - Data upload skipped"
    echo "ğŸ’¡ To upload data after full deployment, run:"
    echo "   ./upload-data.sh --CONNECTION_NAME=$CONNECTION_NAME"
  fi
fi
