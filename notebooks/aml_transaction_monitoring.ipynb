{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AML & Transaction Monitoring Dashboard\n",
        "\n",
        "**Purpose:** Instant-access reports for transaction monitoring alerts, SAR/STR filings, backlog management, and AML risk heatmaps.\n",
        "\n",
        "**Audience:** Chief Compliance Officer, Head of AML, Transaction Monitoring Team, Financial Intelligence Unit (FIU)\n",
        "\n",
        "---\n",
        "\n",
        "## The Regulatory Inquiry Scenario\n",
        "\n",
        "**Tuesday, 10:00 AM.** Email from Financial Intelligence Unit (FIU): *\"We need answers by EOD:**\n",
        "1. **How many transaction monitoring alerts did you have last quarter?**\"\n",
        "2. **\"Are there any overdue or backlogged AML alerts posing regulatory risk?\"**\n",
        "3. **\"Where are you seeing the highest AML/CTF risk (products, countries, channels)?\"**\n",
        "4. **\"What's your SAR/STR filing rate vs. industry benchmark?\"**\n",
        "\n",
        "**Traditional Response:** \"We'll compile data from our monitoring system and get back to you next week...\" (FIU frustrated. Regulatory risk increases.)\n",
        "\n",
        "**With This Notebook:** \"I'll send the full analysis by 2 PM.\" (Runs 3 queries, exports dashboards, FIU impressed with responsiveness.)\n",
        "\n",
        "---\n",
        "\n",
        "## Daily Routine: AML Team Morning Workflow\n",
        "\n",
        "### 7:30 AM - 8:00 AM: Overnight Alert Review\n",
        "- Run Alert Backlog Report\n",
        "- Identify critical alerts requiring same-day investigation\n",
        "- Check SLA Breach List\n",
        "- Review Risk Heatmap\n",
        "\n",
        "### 8:00 AM - 12:00 PM: Alert Investigation & Disposition\n",
        "- Standard workflow: 15-45 minutes per alert\n",
        "- Pull transaction details, review customer profile\n",
        "- Analyze behavioral baseline\n",
        "- Disposition decision: Close, Monitor, or Escalate to SAR\n",
        "\n",
        "### 12:00 PM - 1:00 PM: SAR Filing & Regulatory Submission\n",
        "- Complete SAR form, attach evidence\n",
        "- Submit to FIU via secure portal\n",
        "- SLA: File SAR within 30 days (CH), 15 days (DE), 10 days (AT)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "**Business Context:** Establish secure connection to the AML monitoring platform.\n",
        "\n",
        "**Data Sources:**\n",
        "- `PAYA_AGG_DT_TRANSACTION_ANOMALIES` - Transaction monitoring alerts\n",
        "- `PAYA_AGG_DT_TRANSACTION_ANOMALIES` - Payment transaction universe\n",
        "- `CRMA_AGG_DT_CUSTOMER_360` - Customer risk profiles\n",
        "- `ACCA_AGG_DT_ACCOUNTS` - Account relationships\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Setup: Initialize Snowflake session and Streamlit\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "session = get_active_session()\n",
        "session.use_database('AAA_DEV_SYNTHETIC_BANK')\n",
        "session.use_schema('PAY_AGG_001')\n",
        "st.success('Connected to AML Monitoring Platform')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Question 1: Alert Volume & SAR Filing Metrics\n",
        "\n",
        "**Regulatory Question:** \"How many transaction-monitoring alerts and SAR/STR filings did you have last quarter?\"\n",
        "\n",
        "> **Note:** SAR/STR = Suspicious Activity Report / Suspicious Transaction Report. These are mandatory regulatory filings to Financial Intelligence Units (FIUs) when financial institutions detect transactions that may indicate money laundering, terrorist financing, fraud, or other financial crimes.\n",
        "\n",
        "**Why This Matters:**\n",
        "- **Program Effectiveness:** Demonstrate AML program is functioning properly\n",
        "- **Resource Justification:** Support budget requests for compliance team\n",
        "- **Regulatory Compliance:** Required metrics for annual AML attestation\n",
        "- **Peer Benchmarking:** Compare performance against industry standards\n",
        "\n",
        "**What We're Measuring:**\n",
        "- Total alerts generated (last 90 days)\n",
        "- Alerts per 1,000 transactions (productivity metric)\n",
        "- False positive rate (alert quality)\n",
        "- True positive rate (detection effectiveness)\n",
        "- Estimated SAR filings by jurisdiction\n",
        "- Alerts per SAR ratio (efficiency metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Query: Quarterly Alert & SAR Dashboard\n",
        "query_q1 = '''\n",
        "WITH quarterly_period AS (\n",
        "    -- Use last 90 days of ACTUAL data, not calendar last 90 days\n",
        "    SELECT \n",
        "        DATEADD(day, -90, MAX(VALUE_DATE)) as quarter_start,\n",
        "        MAX(VALUE_DATE) as quarter_end\n",
        "    FROM PAY_RAW_001.PAYI_RAW_TB_TRANSACTIONS\n",
        "),\n",
        "transaction_universe AS (\n",
        "    SELECT \n",
        "        COUNT(DISTINCT t.TRANSACTION_ID) as total_transactions,\n",
        "        COUNT(DISTINCT t.ACCOUNT_ID) as unique_accounts,\n",
        "        SUM(ABS(t.AMOUNT)) as total_volume_usd\n",
        "    FROM PAY_RAW_001.PAYI_RAW_TB_TRANSACTIONS t\n",
        "    CROSS JOIN quarterly_period qp\n",
        "    WHERE t.VALUE_DATE BETWEEN qp.quarter_start AND qp.quarter_end\n",
        "),\n",
        "alert_metrics AS (\n",
        "    SELECT \n",
        "        COUNT(DISTINCT ta.TRANSACTION_ID) as total_alerts,\n",
        "        COUNT(DISTINCT CASE WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'CRITICAL_ANOMALY' THEN ta.TRANSACTION_ID END) as critical_alerts,\n",
        "        COUNT(DISTINCT CASE WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'HIGH_ANOMALY' THEN ta.TRANSACTION_ID END) as high_alerts,\n",
        "        COUNT(DISTINCT CASE WHEN ta.REQUIRES_IMMEDIATE_REVIEW = TRUE THEN ta.TRANSACTION_ID END) as immediate_review_required,\n",
        "        COUNT(DISTINCT CASE \n",
        "            WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'MODERATE_ANOMALY'\n",
        "            THEN ta.TRANSACTION_ID \n",
        "        END) as likely_false_positives,\n",
        "        COUNT(DISTINCT CASE \n",
        "            WHEN ta.OVERALL_ANOMALY_CLASSIFICATION IN ('CRITICAL_ANOMALY', 'HIGH_ANOMALY') \n",
        "            AND ta.REQUIRES_IMMEDIATE_REVIEW = TRUE \n",
        "            THEN ta.TRANSACTION_ID \n",
        "        END) as likely_true_positives\n",
        "    FROM PAYA_AGG_DT_TRANSACTION_ANOMALIES ta\n",
        "    CROSS JOIN quarterly_period qp\n",
        "    WHERE ta.VALUE_DATE BETWEEN qp.quarter_start AND qp.quarter_end\n",
        "      AND ta.OVERALL_ANOMALY_CLASSIFICATION IN ('CRITICAL_ANOMALY', 'HIGH_ANOMALY', 'MODERATE_ANOMALY')\n",
        "),\n",
        "sar_metrics AS (\n",
        "    SELECT \n",
        "        COUNT(DISTINCT ta.CUSTOMER_ID) as estimated_sar_filings,\n",
        "        COUNT(DISTINCT CASE WHEN c.COUNTRY = 'Switzerland' THEN ta.CUSTOMER_ID END) as sar_switzerland,\n",
        "        COUNT(DISTINCT CASE WHEN c.COUNTRY = 'Germany' THEN ta.CUSTOMER_ID END) as sar_germany,\n",
        "        COUNT(DISTINCT CASE WHEN c.COUNTRY = 'Austria' THEN ta.CUSTOMER_ID END) as sar_austria,\n",
        "        COUNT(DISTINCT CASE WHEN c.COUNTRY IN ('Sweden', 'Norway', 'Denmark', 'Finland') THEN ta.CUSTOMER_ID END) as sar_nordics\n",
        "    FROM PAYA_AGG_DT_TRANSACTION_ANOMALIES ta\n",
        "    CROSS JOIN quarterly_period qp\n",
        "    INNER JOIN CRM_AGG_001.CRMA_AGG_DT_CUSTOMER_360 c ON ta.CUSTOMER_ID = c.CUSTOMER_ID\n",
        "    WHERE ta.VALUE_DATE BETWEEN qp.quarter_start AND qp.quarter_end\n",
        "      AND ta.OVERALL_ANOMALY_CLASSIFICATION IN ('CRITICAL_ANOMALY', 'HIGH_ANOMALY')\n",
        "      AND ta.REQUIRES_IMMEDIATE_REVIEW = TRUE\n",
        "      AND c.COUNTRY IS NOT NULL\n",
        ")\n",
        "SELECT \n",
        "    tu.total_transactions,\n",
        "    tu.unique_accounts,\n",
        "    ROUND(tu.total_volume_usd / 1000000, 2) as total_volume_million_usd,\n",
        "    am.total_alerts,\n",
        "    ROUND(am.total_alerts * 1000.0 / NULLIF(tu.total_transactions, 0), 2) as alerts_per_1000_transactions,\n",
        "    am.critical_alerts,\n",
        "    am.high_alerts,\n",
        "    am.immediate_review_required,\n",
        "    am.likely_false_positives,\n",
        "    am.likely_true_positives,\n",
        "    ROUND(am.likely_false_positives * 100.0 / NULLIF(am.total_alerts, 0), 2) as false_positive_rate_pct,\n",
        "    ROUND(am.likely_true_positives * 100.0 / NULLIF(am.total_alerts, 0), 2) as true_positive_rate_pct,\n",
        "    sm.estimated_sar_filings,\n",
        "    ROUND(sm.estimated_sar_filings * 10000.0 / NULLIF(tu.total_transactions, 0), 4) as sar_rate_per_10k_transactions,\n",
        "    sm.sar_switzerland,\n",
        "    sm.sar_germany,\n",
        "    sm.sar_austria,\n",
        "    sm.sar_nordics,\n",
        "    ROUND(am.total_alerts * 1.0 / NULLIF(sm.estimated_sar_filings, 0), 2) as alerts_per_sar_ratio\n",
        "FROM transaction_universe tu\n",
        "CROSS JOIN alert_metrics am\n",
        "CROSS JOIN sar_metrics sm\n",
        "'''\n",
        "\n",
        "df_q1 = session.sql(query_q1).to_pandas()\n",
        "\n",
        "# Get date range info\n",
        "date_range_query = '''\n",
        "SELECT \n",
        "    MIN(VALUE_DATE) as earliest_date,\n",
        "    MAX(VALUE_DATE) as latest_date,\n",
        "    DATEADD(day, -90, MAX(VALUE_DATE)) as analysis_start,\n",
        "    MAX(VALUE_DATE) as analysis_end\n",
        "FROM PAY_RAW_001.PAYI_RAW_TB_TRANSACTIONS\n",
        "'''\n",
        "df_date_range = session.sql(date_range_query).to_pandas()\n",
        "\n",
        "st.subheader('Quarterly Alert & SAR Metrics (Last 90 Days of Data)')\n",
        "st.info(f'''\n",
        "**Analysis Period:** {df_date_range['ANALYSIS_START'].iloc[0].strftime('%Y-%m-%d')} to {df_date_range['ANALYSIS_END'].iloc[0].strftime('%Y-%m-%d')}\n",
        "\n",
        "**Data Available:** {df_date_range['EARLIEST_DATE'].iloc[0].strftime('%Y-%m-%d')} to {df_date_range['LATEST_DATE'].iloc[0].strftime('%Y-%m-%d')}\n",
        "\n",
        "_Note: This analysis uses the last 90 days of your actual transaction data, not the calendar last 90 days._\n",
        "''')\n",
        "st.dataframe(df_q1, use_container_width=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Alert Performance Dashboard\n",
        "\n",
        "**Business Context:** Key performance indicators for AML program effectiveness and efficiency.\n",
        "\n",
        "**Industry Benchmarks:**\n",
        "- Alerts per 1,000 transactions: 8-12 (Better than industry avg: 15-25)\n",
        "- False positive rate: 15-20% (Better than industry avg: 35-50%)\n",
        "- SAR rate per 10K transactions: 2-5 (Comparable to industry avg: 3-8)\n",
        "- Alerts per SAR: 15-20 (More efficient than industry avg: 25-50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Alert Performance Metrics\n",
        "total_txn = df_q1['TOTAL_TRANSACTIONS'].iloc[0]\n",
        "total_alerts = df_q1['TOTAL_ALERTS'].iloc[0]\n",
        "alerts_per_1k = df_q1['ALERTS_PER_1000_TRANSACTIONS'].iloc[0] if not pd.isna(df_q1['ALERTS_PER_1000_TRANSACTIONS'].iloc[0]) else 0\n",
        "critical = df_q1['CRITICAL_ALERTS'].iloc[0]\n",
        "high = df_q1['HIGH_ALERTS'].iloc[0]\n",
        "fp_rate = df_q1['FALSE_POSITIVE_RATE_PCT'].iloc[0] if not pd.isna(df_q1['FALSE_POSITIVE_RATE_PCT'].iloc[0]) else 0\n",
        "tp_rate = df_q1['TRUE_POSITIVE_RATE_PCT'].iloc[0] if not pd.isna(df_q1['TRUE_POSITIVE_RATE_PCT'].iloc[0]) else 0\n",
        "\n",
        "st.subheader('Alert Performance Metrics')\n",
        "\n",
        "if total_txn == 0:\n",
        "    st.warning('‚ö†Ô∏è No transactions found in the analysis period. Please check that transaction data exists.')\n",
        "else:\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "        st.metric('Total Transactions', f'{int(total_txn):,}', help='Transaction universe (last 90 days of data)')\n",
        "        st.metric('Total Alerts', f'{int(total_alerts):,}', help='All monitoring alerts generated')\n",
        "        st.metric('Alerts per 1K Txn', f'{alerts_per_1k:.2f}', help='Productivity metric (Target: 8-12)')\n",
        "    \n",
        "    with col2:\n",
        "        st.metric('Critical Alerts', f'{int(critical):,}', help='Requires immediate investigation')\n",
        "        st.metric('High Alerts', f'{int(high):,}', help='Priority investigation within 15 days')\n",
        "        \n",
        "        # Alert quality assessment\n",
        "        if alerts_per_1k <= 12:\n",
        "            st.success('Alert volume within target')\n",
        "        elif alerts_per_1k <= 15:\n",
        "            st.warning('Alert volume above target')\n",
        "        else:\n",
        "            st.error('Alert volume excessive - tune rules')\n",
        "    \n",
        "    with col3:\n",
        "        st.metric('False Positive Rate', f'{fp_rate:.1f}%', help='Target: <20%')\n",
        "        st.metric('True Positive Rate', f'{tp_rate:.1f}%', help='Detection effectiveness')\n",
        "        \n",
        "        # False positive assessment\n",
        "        if fp_rate <= 20:\n",
        "            st.success('Alert quality excellent')\n",
        "        elif fp_rate <= 30:\n",
        "            st.warning('Alert quality needs improvement')\n",
        "        else:\n",
        "            st.error('High false positive rate - review rules')\n",
        "    \n",
        "    # Alert Breakdown Chart\n",
        "    st.subheader('Alert Severity Distribution')\n",
        "    moderate = total_alerts - critical - high\n",
        "    alert_dist = pd.DataFrame({\n",
        "        'Severity': ['Critical', 'High', 'Moderate'],\n",
        "        'Count': [int(critical), int(high), int(moderate)]\n",
        "    })\n",
        "    st.bar_chart(alert_dist.set_index('Severity'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. SAR/STR Filing Metrics\n",
        "\n",
        "**Business Context:** Suspicious Activity Report filing statistics for regulatory reporting.\n",
        "\n",
        "**Regulatory Requirements:**\n",
        "- Switzerland (CH): File within 30 days of suspicion\n",
        "- Germany (DE): File within 15 days\n",
        "- Austria (AT): File within 10 days\n",
        "- Nordic countries: Varies by jurisdiction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# SAR Filing Metrics\n",
        "total_sars = df_q1['ESTIMATED_SAR_FILINGS'].iloc[0]\n",
        "sar_rate = df_q1['SAR_RATE_PER_10K_TRANSACTIONS'].iloc[0]\n",
        "alerts_per_sar = df_q1['ALERTS_PER_SAR_RATIO'].iloc[0]\n",
        "sar_ch = df_q1['SAR_SWITZERLAND'].iloc[0]\n",
        "sar_de = df_q1['SAR_GERMANY'].iloc[0]\n",
        "sar_at = df_q1['SAR_AUSTRIA'].iloc[0]\n",
        "sar_nordic = df_q1['SAR_NORDICS'].iloc[0]\n",
        "\n",
        "# Diagnostic: Check what countries actually exist\n",
        "diagnostic_query = '''\n",
        "SELECT \n",
        "    c.COUNTRY,\n",
        "    COUNT(DISTINCT ta.CUSTOMER_ID) as customer_count\n",
        "FROM PAYA_AGG_DT_TRANSACTION_ANOMALIES ta\n",
        "INNER JOIN CRM_AGG_001.CRMA_AGG_DT_CUSTOMER_360 c ON ta.CUSTOMER_ID = c.CUSTOMER_ID\n",
        "WHERE ta.OVERALL_ANOMALY_CLASSIFICATION IN ('CRITICAL_ANOMALY', 'HIGH_ANOMALY')\n",
        "  AND ta.REQUIRES_IMMEDIATE_REVIEW = TRUE\n",
        "  AND c.COUNTRY IS NOT NULL\n",
        "GROUP BY c.COUNTRY\n",
        "ORDER BY customer_count DESC\n",
        "'''\n",
        "df_countries = session.sql(diagnostic_query).to_pandas()\n",
        "\n",
        "st.subheader('SAR/STR Filing Metrics')\n",
        "\n",
        "if len(df_countries) > 0:\n",
        "    st.info(f\"**Country Data Found:** {len(df_countries)} countries detected. Top: {', '.join(df_countries['COUNTRY'].head(5).tolist())}\")\n",
        "    with st.expander(\"üîç View All Countries in SAR Data\"):\n",
        "        st.dataframe(df_countries, use_container_width=True)\n",
        "else:\n",
        "    st.error(\"‚ùå No country data found! Customer records may lack country information or CRMA_AGG_DT_CUSTOMER_360 needs refresh.\")\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.metric('Estimated SAR Filings', f'{total_sars:,}', help='High-risk customers with confirmed anomalies')\n",
        "    st.metric('SAR Rate (per 10K txn)', f'{sar_rate:.4f}', help='Industry benchmark: 3-8')\n",
        "    st.metric('Alerts per SAR', f'{alerts_per_sar:.1f}', help='Efficiency metric (Target: 15-20)')\n",
        "\n",
        "with col2:\n",
        "    st.markdown('**SAR Filings by Jurisdiction:**')\n",
        "    st.metric('Switzerland (CH)', f'{sar_ch:,}', help='30-day filing requirement')\n",
        "    st.metric('Germany (DE)', f'{sar_de:,}', help='15-day filing requirement')\n",
        "    st.metric('Austria (AT)', f'{sar_at:,}', help='10-day filing requirement')\n",
        "    st.metric('Nordic Countries', f'{sar_nordic:,}', help='SE, NO, DK, FI')\n",
        "\n",
        "# SAR Distribution by Jurisdiction\n",
        "st.subheader('SAR Distribution by Jurisdiction')\n",
        "sar_dist = pd.DataFrame({\n",
        "    'Jurisdiction': ['Switzerland', 'Germany', 'Austria', 'Nordic'],\n",
        "    'Count': [sar_ch, sar_de, sar_at, sar_nordic]\n",
        "})\n",
        "st.bar_chart(sar_dist.set_index('Jurisdiction'))\n",
        "\n",
        "st.info(f'''\n",
        "**Program Efficiency Analysis:**\n",
        "- Alerts per SAR: {alerts_per_sar:.1f} (Industry avg: 25-50)\n",
        "- Interpretation: Every {alerts_per_sar:.0f} alerts generate 1 SAR filing\n",
        "- Status: {\"Excellent efficiency\" if alerts_per_sar < 20 else \"Above industry average\" if alerts_per_sar < 25 else \"Review alert tuning\"}\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Question 2: Alert Backlog & SLA Breach Analysis\n",
        "\n",
        "**Regulatory Question:** \"Are there any overdue or backlogged AML alerts posing regulatory risk?\"\n",
        "\n",
        "**Why This Matters:**\n",
        "- **Regulatory Risk:** Overdue alerts indicate control weaknesses\n",
        "- **Resource Management:** Backlog indicates staffing needs\n",
        "- **Audit Defense:** Demonstrate timely investigation and disposition\n",
        "\n",
        "**SLA Policy:**\n",
        "- Critical alerts: 5 days\n",
        "- High alerts: 15 days\n",
        "- Moderate alerts: 30 days\n",
        "\n",
        "**What We're Measuring:**\n",
        "- Total open alerts by severity\n",
        "- Average and maximum alert age\n",
        "- SLA breach count and percentage\n",
        "- Aging distribution (0-7, 8-30, 31-90, 90+ days)\n",
        "- Regional backlog breakdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Query: Alert Backlog & SLA Breach Report\n",
        "query_q2 = '''\n",
        "WITH open_alerts AS (\n",
        "    SELECT \n",
        "        ta.TRANSACTION_ID,\n",
        "        ta.CUSTOMER_ID,\n",
        "        ta.VALUE_DATE,\n",
        "        ta.OVERALL_ANOMALY_CLASSIFICATION as alert_severity,\n",
        "        ta.REQUIRES_IMMEDIATE_REVIEW,\n",
        "        DATEDIFF(day, ta.VALUE_DATE, CURRENT_DATE()) as alert_age_days,\n",
        "        CASE \n",
        "            WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'CRITICAL_ANOMALY' THEN 5\n",
        "            WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'HIGH_ANOMALY' THEN 15\n",
        "            ELSE 30\n",
        "        END as sla_days,\n",
        "        CASE \n",
        "            WHEN DATEDIFF(day, ta.VALUE_DATE, CURRENT_DATE()) > \n",
        "                 CASE \n",
        "                     WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'CRITICAL_ANOMALY' THEN 5\n",
        "                     WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'HIGH_ANOMALY' THEN 15\n",
        "                     ELSE 30\n",
        "                 END\n",
        "            THEN TRUE ELSE FALSE \n",
        "        END as is_sla_breach,\n",
        "        CASE \n",
        "            WHEN DATEDIFF(day, ta.VALUE_DATE, CURRENT_DATE()) <= 7 THEN '0-7_DAYS'\n",
        "            WHEN DATEDIFF(day, ta.VALUE_DATE, CURRENT_DATE()) <= 30 THEN '8-30_DAYS'\n",
        "            WHEN DATEDIFF(day, ta.VALUE_DATE, CURRENT_DATE()) <= 90 THEN '31-90_DAYS'\n",
        "            ELSE '90_PLUS_DAYS'\n",
        "        END as aging_bucket,\n",
        "        c.COUNTRY,\n",
        "        CASE \n",
        "            WHEN c.COUNTRY IN ('Sweden', 'Norway', 'Denmark', 'Finland') THEN 'NORDIC'\n",
        "            WHEN c.COUNTRY IN ('Germany', 'Austria', 'Switzerland') THEN 'CENTRAL_EUROPE'\n",
        "            ELSE 'OTHER'\n",
        "        END as region\n",
        "    FROM PAYA_AGG_DT_TRANSACTION_ANOMALIES ta\n",
        "    LEFT JOIN CRM_AGG_001.ACCA_AGG_DT_ACCOUNTS acc ON ta.ACCOUNT_ID = acc.ACCOUNT_ID\n",
        "    LEFT JOIN CRM_AGG_001.CRMA_AGG_DT_CUSTOMER_360 c ON acc.CUSTOMER_ID = c.CUSTOMER_ID\n",
        "    WHERE ta.OVERALL_ANOMALY_CLASSIFICATION IN ('CRITICAL_ANOMALY', 'HIGH_ANOMALY', 'MODERATE_ANOMALY')\n",
        ")\n",
        "SELECT \n",
        "    COUNT(*) as total_open_alerts,\n",
        "    ROUND(AVG(alert_age_days), 1) as avg_age_days,\n",
        "    MAX(alert_age_days) as oldest_alert_days,\n",
        "    COUNT(CASE WHEN alert_severity = 'CRITICAL_ANOMALY' THEN 1 END) as critical_open,\n",
        "    COUNT(CASE WHEN alert_severity = 'HIGH_ANOMALY' THEN 1 END) as high_open,\n",
        "    COUNT(CASE WHEN alert_severity = 'MODERATE_ANOMALY' THEN 1 END) as moderate_open,\n",
        "    COUNT(CASE WHEN is_sla_breach = TRUE THEN 1 END) as sla_breach_count,\n",
        "    ROUND(COUNT(CASE WHEN is_sla_breach = TRUE THEN 1 END) * 100.0 / NULLIF(COUNT(*), 0), 2) as sla_breach_percentage,\n",
        "    COUNT(CASE WHEN aging_bucket = '0-7_DAYS' THEN 1 END) as alerts_0_7_days,\n",
        "    COUNT(CASE WHEN aging_bucket = '8-30_DAYS' THEN 1 END) as alerts_8_30_days,\n",
        "    COUNT(CASE WHEN aging_bucket = '31-90_DAYS' THEN 1 END) as alerts_31_90_days,\n",
        "    COUNT(CASE WHEN aging_bucket = '90_PLUS_DAYS' THEN 1 END) as alerts_90_plus_days,\n",
        "    COUNT(CASE WHEN region = 'NORDIC' THEN 1 END) as nordic_backlog,\n",
        "    COUNT(CASE WHEN region = 'CENTRAL_EUROPE' THEN 1 END) as central_europe_backlog,\n",
        "    COUNT(CASE WHEN region = 'OTHER' THEN 1 END) as other_backlog\n",
        "FROM open_alerts\n",
        "'''\n",
        "\n",
        "df_q2 = session.sql(query_q2).to_pandas()\n",
        "st.subheader('Alert Backlog & SLA Breach Analysis')\n",
        "st.dataframe(df_q2, use_container_width=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Backlog Management Dashboard\n",
        "\n",
        "**Business Context:** Operational metrics for alert investigation workload and SLA compliance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Backlog Metrics\n",
        "total_open = df_q2['TOTAL_OPEN_ALERTS'].iloc[0]\n",
        "avg_age = df_q2['AVG_AGE_DAYS'].iloc[0]\n",
        "oldest = df_q2['OLDEST_ALERT_DAYS'].iloc[0]\n",
        "crit_open = df_q2['CRITICAL_OPEN'].iloc[0]\n",
        "high_open = df_q2['HIGH_OPEN'].iloc[0]\n",
        "mod_open = df_q2['MODERATE_OPEN'].iloc[0]\n",
        "sla_breach = df_q2['SLA_BREACH_COUNT'].iloc[0]\n",
        "sla_breach_pct = df_q2['SLA_BREACH_PERCENTAGE'].iloc[0]\n",
        "\n",
        "st.subheader('Backlog Overview')\n",
        "col1, col2, col3 = st.columns(3)\n",
        "\n",
        "with col1:\n",
        "    st.metric('Total Open Alerts', f'{total_open:,}', help='Current investigation backlog')\n",
        "    st.metric('Critical Open', f'{crit_open:,}', help='Requires investigation within 5 days')\n",
        "    st.metric('High Open', f'{high_open:,}', help='Requires investigation within 15 days')\n",
        "\n",
        "with col2:\n",
        "    st.metric('Average Age', f'{avg_age:.1f} days', help='Mean alert age across all open alerts')\n",
        "    st.metric('Oldest Alert', f'{oldest:.0f} days', help='Maximum alert age - requires escalation')\n",
        "    \n",
        "    if oldest > 90:\n",
        "        st.error('CRITICAL: Alerts over 90 days old')\n",
        "    elif oldest > 60:\n",
        "        st.warning('WARNING: Alerts over 60 days old')\n",
        "    else:\n",
        "        st.success('Alert aging under control')\n",
        "\n",
        "with col3:\n",
        "    st.metric('SLA Breaches', f'{sla_breach:,}', f'{sla_breach_pct:.1f}%')\n",
        "    \n",
        "    if sla_breach_pct > 10:\n",
        "        st.error('CRITICAL: >10% SLA breach rate')\n",
        "    elif sla_breach_pct > 5:\n",
        "        st.warning('WARNING: >5% SLA breach rate')\n",
        "    else:\n",
        "        st.success('SLA compliance acceptable')\n",
        "    \n",
        "    # Resource calculation\n",
        "    ftes_needed = total_open / 30 if total_open > 0 else 0  # Assume 30 alerts/month per FTE\n",
        "    st.metric('Est. FTEs Needed', f'{ftes_needed:.1f}', help='At 30 alerts/month per investigator')\n",
        "\n",
        "# Aging Distribution\n",
        "st.subheader('Alert Aging Distribution')\n",
        "aging_df = pd.DataFrame({\n",
        "    'Age Bucket': ['0-7 days', '8-30 days', '31-90 days', '90+ days'],\n",
        "    'Count': [\n",
        "        df_q2['ALERTS_0_7_DAYS'].iloc[0],\n",
        "        df_q2['ALERTS_8_30_DAYS'].iloc[0],\n",
        "        df_q2['ALERTS_31_90_DAYS'].iloc[0],\n",
        "        df_q2['ALERTS_90_PLUS_DAYS'].iloc[0]\n",
        "    ]\n",
        "})\n",
        "st.bar_chart(aging_df.set_index('Age Bucket'))\n",
        "\n",
        "# Regional Backlog\n",
        "st.subheader('Backlog by Region')\n",
        "region_df = pd.DataFrame({\n",
        "    'Region': ['Nordic', 'Central Europe', 'Other'],\n",
        "    'Count': [\n",
        "        df_q2['NORDIC_BACKLOG'].iloc[0],\n",
        "        df_q2['CENTRAL_EUROPE_BACKLOG'].iloc[0],\n",
        "        df_q2['OTHER_BACKLOG'].iloc[0]\n",
        "    ]\n",
        "})\n",
        "st.bar_chart(region_df.set_index('Region'))\n",
        "\n",
        "st.warning(f'''\n",
        "**Remediation Plan:**\n",
        "- Daily closure target: {int(total_open / 30) if total_open > 0 else 0} alerts/day to clear backlog in 30 days\n",
        "- Priority: {crit_open:,} critical alerts (5-day SLA)\n",
        "- Secondary: {high_open:,} high alerts (15-day SLA)\n",
        "- Routine: {mod_open:,} moderate alerts (30-day SLA)\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Question 3: AML/CTF Risk Heatmap\n",
        "\n",
        "**Regulatory Question:** \"Where are you seeing the highest AML/CTF risk?\"\n",
        "\n",
        "**Why This Matters:**\n",
        "- **Targeted Monitoring:** Focus resources on highest-risk areas\n",
        "- **Rule Tuning:** Adjust monitoring rules based on risk concentrations\n",
        "- **Strategic Planning:** Inform business decisions on product/market exposure\n",
        "\n",
        "**Risk Dimensions:**\n",
        "- Country risk (geographic concentration)\n",
        "- Transaction amount tiers (high-value risk)\n",
        "- Customer type (PEP, high-risk, standard)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Query: Multi-Dimensional Risk Heatmap\n",
        "query_q3 = '''\n",
        "WITH risk_by_country AS (\n",
        "    SELECT \n",
        "        c.COUNTRY,\n",
        "        COUNT(DISTINCT CASE WHEN ta.TRANSACTION_ID IS NOT NULL THEN ta.TRANSACTION_ID END) as alert_count,\n",
        "        COUNT(DISTINCT t.TRANSACTION_ID) as total_transactions,\n",
        "        ROUND(COUNT(DISTINCT CASE WHEN ta.TRANSACTION_ID IS NOT NULL THEN ta.TRANSACTION_ID END) * 100.0 / \n",
        "              NULLIF(COUNT(DISTINCT t.TRANSACTION_ID), 0), 2) as alert_rate_pct,\n",
        "        SUM(CASE WHEN ta.OVERALL_ANOMALY_CLASSIFICATION = 'CRITICAL_ANOMALY' THEN 1 ELSE 0 END) as critical_alerts,\n",
        "        ROUND(AVG(ta.COMPOSITE_ANOMALY_SCORE), 2) as avg_risk_score\n",
        "    FROM PAY_RAW_001.PAYI_RAW_TB_TRANSACTIONS t\n",
        "    LEFT JOIN CRM_RAW_001.ACCI_RAW_TB_ACCOUNTS acc ON t.ACCOUNT_ID = acc.ACCOUNT_ID\n",
        "    LEFT JOIN CRM_AGG_001.CRMA_AGG_DT_CUSTOMER_360 c ON acc.CUSTOMER_ID = c.CUSTOMER_ID\n",
        "    LEFT JOIN PAYA_AGG_DT_TRANSACTION_ANOMALIES ta ON t.TRANSACTION_ID = ta.TRANSACTION_ID\n",
        "    WHERE c.COUNTRY IS NOT NULL\n",
        "    GROUP BY c.COUNTRY\n",
        "),\n",
        "risk_by_amount_tier AS (\n",
        "    SELECT \n",
        "        CASE \n",
        "            WHEN t.AMOUNT >= 100000 THEN 'TIER_1_>100K'\n",
        "            WHEN t.AMOUNT >= 10000 THEN 'TIER_2_10K-100K'\n",
        "            WHEN t.AMOUNT >= 1000 THEN 'TIER_3_1K-10K'\n",
        "            ELSE 'TIER_4_<1K'\n",
        "        END as amount_tier,\n",
        "        COUNT(DISTINCT CASE WHEN ta.TRANSACTION_ID IS NOT NULL THEN ta.TRANSACTION_ID END) as alert_count,\n",
        "        COUNT(DISTINCT t.TRANSACTION_ID) as total_transactions,\n",
        "        ROUND(COUNT(DISTINCT CASE WHEN ta.TRANSACTION_ID IS NOT NULL THEN ta.TRANSACTION_ID END) * 100.0 / \n",
        "              NULLIF(COUNT(DISTINCT t.TRANSACTION_ID), 0), 2) as alert_rate_pct,\n",
        "        ROUND(AVG(t.AMOUNT), 2) as avg_transaction_amount\n",
        "    FROM PAY_RAW_001.PAYI_RAW_TB_TRANSACTIONS t\n",
        "    LEFT JOIN PAYA_AGG_DT_TRANSACTION_ANOMALIES ta ON t.TRANSACTION_ID = ta.TRANSACTION_ID\n",
        "    GROUP BY amount_tier\n",
        "),\n",
        "risk_by_customer_type AS (\n",
        "    SELECT \n",
        "        CASE \n",
        "            WHEN c.EXPOSED_PERSON_MATCH_TYPE IN ('EXACT_MATCH','FUZZY_MATCH') THEN 'PEP'\n",
        "            WHEN c.RISK_CLASSIFICATION IN ('CRITICAL', 'HIGH') THEN 'HIGH_RISK'\n",
        "            ELSE 'STANDARD'\n",
        "        END as customer_type,\n",
        "        COUNT(DISTINCT CASE WHEN ta.TRANSACTION_ID IS NOT NULL THEN ta.TRANSACTION_ID END) as alert_count,\n",
        "        COUNT(DISTINCT t.TRANSACTION_ID) as total_transactions,\n",
        "        ROUND(COUNT(DISTINCT CASE WHEN ta.TRANSACTION_ID IS NOT NULL THEN ta.TRANSACTION_ID END) * 100.0 / \n",
        "              NULLIF(COUNT(DISTINCT t.TRANSACTION_ID), 0), 2) as alert_rate_pct\n",
        "    FROM PAY_RAW_001.PAYI_RAW_TB_TRANSACTIONS t\n",
        "    LEFT JOIN CRM_RAW_001.ACCI_RAW_TB_ACCOUNTS acc ON t.ACCOUNT_ID = acc.ACCOUNT_ID\n",
        "    LEFT JOIN CRM_AGG_001.CRMA_AGG_DT_CUSTOMER_360 c ON acc.CUSTOMER_ID = c.CUSTOMER_ID\n",
        "    LEFT JOIN PAYA_AGG_DT_TRANSACTION_ANOMALIES ta ON t.TRANSACTION_ID = ta.TRANSACTION_ID\n",
        "    GROUP BY customer_type\n",
        "),\n",
        "ranked_country_risk AS (\n",
        "    SELECT \n",
        "        'COUNTRY_RISK' as risk_dimension,\n",
        "        COUNTRY as category,\n",
        "        alert_count,\n",
        "        total_transactions,\n",
        "        alert_rate_pct,\n",
        "        critical_alerts as detail_metric,\n",
        "        ROW_NUMBER() OVER (ORDER BY alert_rate_pct DESC) as rank\n",
        "    FROM risk_by_country\n",
        ")\n",
        "SELECT \n",
        "    risk_dimension,\n",
        "    category,\n",
        "    alert_count,\n",
        "    total_transactions,\n",
        "    alert_rate_pct,\n",
        "    detail_metric\n",
        "FROM ranked_country_risk\n",
        "WHERE rank <= 10\n",
        "\n",
        "UNION ALL\n",
        "\n",
        "SELECT \n",
        "    'AMOUNT_TIER' as risk_dimension,\n",
        "    amount_tier as category,\n",
        "    alert_count,\n",
        "    total_transactions,\n",
        "    alert_rate_pct,\n",
        "    avg_transaction_amount as detail_metric\n",
        "FROM risk_by_amount_tier\n",
        "\n",
        "UNION ALL\n",
        "\n",
        "SELECT \n",
        "    'CUSTOMER_TYPE' as risk_dimension,\n",
        "    customer_type as category,\n",
        "    alert_count,\n",
        "    total_transactions,\n",
        "    alert_rate_pct,\n",
        "    NULL as detail_metric\n",
        "FROM risk_by_customer_type\n",
        "'''\n",
        "\n",
        "df_q3 = session.sql(query_q3).to_pandas()\n",
        "st.subheader('AML Risk Heatmap (Multi-Dimensional)')\n",
        "st.dataframe(df_q3, use_container_width=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Risk Heatmap Visualizations\n",
        "\n",
        "**Business Context:** Visual risk concentrations for executive presentations and strategic planning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Country Risk\n",
        "st.subheader('Top 10 Countries by Alert Rate')\n",
        "df_country = df_q3[df_q3['RISK_DIMENSION'] == 'COUNTRY_RISK'].copy()\n",
        "if len(df_country) > 0:\n",
        "    country_chart = df_country.set_index('CATEGORY')[['ALERT_RATE_PCT']].head(10)\n",
        "    st.bar_chart(country_chart)\n",
        "    \n",
        "    st.info(f'''\n",
        "    **Top Risk Countries:**\n",
        "    - Highest alert rate: {df_country.iloc[0]['CATEGORY']} ({df_country.iloc[0]['ALERT_RATE_PCT']:.2f}%)\n",
        "    - Total alerts in top country: {int(df_country.iloc[0]['ALERT_COUNT']):,}\n",
        "    - Recommendation: Consider enhanced monitoring for {df_country.iloc[0]['CATEGORY']} customers\n",
        "    ''')\n",
        "else:\n",
        "    st.warning('No country risk data available')\n",
        "\n",
        "# Amount Tier Risk\n",
        "st.subheader('Risk by Transaction Amount Tier')\n",
        "df_amount = df_q3[df_q3['RISK_DIMENSION'] == 'AMOUNT_TIER'].copy()\n",
        "if len(df_amount) > 0:\n",
        "    # Sort by tier for logical display\n",
        "    tier_order = ['TIER_1_>100K', 'TIER_2_10K-100K', 'TIER_3_1K-10K', 'TIER_4_<1K']\n",
        "    df_amount['CATEGORY'] = pd.Categorical(df_amount['CATEGORY'], categories=tier_order, ordered=True)\n",
        "    df_amount = df_amount.sort_values('CATEGORY')\n",
        "    amount_chart = df_amount.set_index('CATEGORY')[['ALERT_RATE_PCT']]\n",
        "    st.bar_chart(amount_chart)\n",
        "    \n",
        "    highest_tier = df_amount.loc[df_amount['ALERT_RATE_PCT'].idxmax()]\n",
        "    st.info(f'''\n",
        "    **Transaction Amount Risk:**\n",
        "    - Highest alert rate: {highest_tier['CATEGORY']} ({highest_tier['ALERT_RATE_PCT']:.2f}%)\n",
        "    - Alert count: {int(highest_tier['ALERT_COUNT']):,}\n",
        "    - Interpretation: {\"Large transactions require enhanced scrutiny\" if \">100K\" in highest_tier['CATEGORY'] else \"Standard transaction monitoring effective\"}\n",
        "    ''')\n",
        "else:\n",
        "    st.warning('No amount tier data available')\n",
        "\n",
        "# Customer Type Risk\n",
        "st.subheader('Risk by Customer Type')\n",
        "df_customer = df_q3[df_q3['RISK_DIMENSION'] == 'CUSTOMER_TYPE'].copy()\n",
        "if len(df_customer) > 0:\n",
        "    customer_chart = df_customer.set_index('CATEGORY')[['ALERT_RATE_PCT']]\n",
        "    st.bar_chart(customer_chart)\n",
        "    \n",
        "    pep_row = df_customer[df_customer['CATEGORY'] == 'PEP']\n",
        "    if len(pep_row) > 0:\n",
        "        pep_rate = pep_row.iloc[0]['ALERT_RATE_PCT']\n",
        "        st.warning(f'''\n",
        "        **PEP Risk Profile:**\n",
        "        - PEP alert rate: {pep_rate:.2f}%\n",
        "        - PEP alerts: {int(pep_row.iloc[0]['ALERT_COUNT']):,}\n",
        "        - Status: {\"Within expected range\" if pep_rate < 10 else \"Elevated - review PEP monitoring\"}\n",
        "        - Recommendation: PEPs require enhanced due diligence and source of wealth verification\n",
        "        ''')\n",
        "else:\n",
        "    st.warning('No customer type data available')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Comprehensive AML Evidence Package\n",
        "\n",
        "**Purpose:** Export all 3 AML reports for FIU submissions and regulatory inquiries.\n",
        "\n",
        "**Contents:**\n",
        "1. Quarterly Alert & SAR Dashboard\n",
        "2. Alert Backlog & SLA Breach Report\n",
        "3. Multi-Dimensional Risk Heatmap\n",
        "4. Metadata (timestamp, preparer, reporting period)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Comprehensive Export Package\n",
        "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "filename = f'AML_Transaction_Monitoring_Evidence_{ts}.csv'\n",
        "\n",
        "# Combine all reports\n",
        "export_package = pd.concat([\n",
        "    df_q1.assign(REPORT='1_QUARTERLY_ALERTS_SAR'),\n",
        "    df_q2.assign(REPORT='2_BACKLOG_SLA_BREACH'),\n",
        "    df_q3.assign(REPORT='3_RISK_HEATMAP')\n",
        "], ignore_index=True)\n",
        "\n",
        "# Add metadata\n",
        "export_package['REPORT_DATE'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "export_package['REPORTING_PERIOD'] = 'Last 90 Days'\n",
        "export_package['PREPARED_BY'] = 'Chief Compliance Officer / Head of AML'\n",
        "export_package['REGULATORY_FRAMEWORK'] = 'AML/CTF Regulations | FIU Reporting Requirements | SAR/STR Obligations'\n",
        "\n",
        "csv_data = export_package.to_csv(index=False)\n",
        "\n",
        "st.download_button(\n",
        "    label='Download Complete AML Evidence Package (CSV)',\n",
        "    data=csv_data,\n",
        "    file_name=filename,\n",
        "    mime='text/csv'\n",
        ")\n",
        "\n",
        "st.success(f'''\n",
        "**AML Evidence Package Ready**\n",
        "\n",
        "**File:** {filename}  \n",
        "**Timestamp:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}  \n",
        "**Reports Included:** 3 (Alerts/SAR, Backlog, Risk Heatmap)  \n",
        "**Retention Period:** 7 years (regulatory requirement)  \n",
        "**Audit Trail:** Complete\n",
        "\n",
        "**FIU Inquiry Readiness:**\n",
        "- Alert metrics: Ready\n",
        "- Backlog analysis: Complete\n",
        "- Risk heatmap: Generated\n",
        "- SAR filings: Documented\n",
        "\n",
        "**Next Steps:**\n",
        "1. Save to secure AML documentation repository\n",
        "2. Share with FIU as needed\n",
        "3. Include in quarterly management reporting\n",
        "4. Update AML program effectiveness assessment\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways for CCO\n",
        "\n",
        "**Always have these 3 reports ready:**\n",
        "1. Quarterly Alert & SAR Dashboard\n",
        "2. Alert Backlog & SLA Breach Report  \n",
        "3. AML Risk Heatmap\n",
        "\n",
        "**Response time targets:**\n",
        "- Critical alert triage: <4 hours\n",
        "- Alert investigation: 15-45 minutes per alert\n",
        "- SAR filing: Within statutory deadline (10-30 days by jurisdiction)\n",
        "- Regulator inquiry: <24 hours for summary, <5 days for detailed evidence\n",
        "\n",
        "**Quality metrics to monitor:**\n",
        "- **False positive rate:** Target <20% (Industry avg: 35-50%)\n",
        "- **Alerts per 1,000 transactions:** Target <12 (Industry avg: 15-25)\n",
        "- **SLA compliance:** Target >95% alerts closed within SLA\n",
        "- **SAR quality:** Target 0 rejected SARs\n",
        "\n",
        "**Escalation Protocols:**\n",
        "\n",
        "### Level 1: Same-Day Escalation\n",
        "**Triggers:** Critical alert with cross-border SWIFT transfer >‚Ç¨100K, PEP customer with structuring pattern, Alert age >30 days (SLA breach)\n",
        "**Action:** Email Head of AML + CCO with transaction details + recommended action\n",
        "\n",
        "### Level 2: Weekly Escalation (Monday Morning)\n",
        "**Triggers:** Backlog >50 alerts, SLA breach rate >10%, False positive rate >30%\n",
        "**Action:** Weekly AML committee meeting with remediation plan\n",
        "\n",
        "### Level 3: Regulatory Escalation (Immediate)\n",
        "**Triggers:** FIU inquiry received, Suspicious activity linked to ongoing criminal investigation, Material breach of AML procedures\n",
        "**Action:** Notify CCO, CRO, General Counsel immediately. Prepare regulatory response within 24 hours.\n",
        "\n",
        "---\n",
        "\n",
        "**Last Updated:** December 2025  \n",
        "**Owner:** Chief Compliance Officer  \n",
        "**Reviewers:** Head of AML, Transaction Monitoring Manager, FIU Liaison"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
